{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "import time\n",
    "import random\n",
    "RANDOM_SEED = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/bin/python: No module named pip3\n",
      "/anaconda3/bin/python: No module named pip3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip3 install --upgrade pip\n",
    "!{sys.executable} -m pip3 install python-mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "def euclideanDistance (x,y):\n",
    "    if len(x.shape)==1: return np.sqrt(np.sum(np.square(x-y)))\n",
    "    else: return np.sqrt(np.sum((np.square(x - y)), axis = 1))\n",
    "\n",
    "'''\n",
    "def getKNeighbours(testX, X, K, distanceMetric):\n",
    "    dists = distanceMetric(X, testX);\n",
    "    ind = np.argpartition(dists, K)[0:K]\n",
    "    return ind\n",
    "'''\n",
    "\n",
    "def getKNeighbours(testX, X, K, distanceMetric):\n",
    "    #testX is a matrix\n",
    "    dists = np.array([distanceMetric(X, testx) for testx in testX])\n",
    "    ind = np.argpartition(dists, K, axis = 1)[:, 0:K]\n",
    "    return ind\n",
    "\n",
    "\n",
    "def knnClassifier(testX,trainX,trainY, K, distanceMetric):    \n",
    "    indices = getKNeighbours(testX, trainX, K, distanceMetric)\n",
    "    freqs = np.array([trainY[index] for index in indices])\n",
    "    predY = [np.bincount(freq).argmax() for freq in freqs]\n",
    "    return np.array(predY)\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes\n",
    "    \n",
    "\n",
    "def parzenWindowEstimation_gaussian(testX, trainX, h):\n",
    "    #each vector is d-dimensional\n",
    "    #testX: (n,d), trainX: (m,d)\n",
    "    d = trainX.shape[1]\n",
    "\n",
    "    estimates = [np.mean(np.exp(-np.sum(np.square((testx - trainX)), axis = 1)/(2*(h*h)))/(np.float_power(np.sqrt(2*np.pi), d)*h)) for testx in testX]\n",
    "    return np.array(estimates)\n",
    "    \n",
    "def bayesClassifier(testX, trainX, trainY, estimator, h = 1):\n",
    "    A, priors = np.unique(trainY, return_counts = True)\n",
    "    q = np.array([priors[idx]*parzenWindowEstimation_gaussian(testX, trainX[np.where(trainY == A[idx])], h) for idx in range(len(A))])\n",
    "    return np.array([A[idx] for idx in np.argmax(q, axis = 0)])\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Metrics\n",
    "\n",
    "def accuracy(prediction, actual):\n",
    "    return np.sum(prediction==actual)/prediction.shape[0]\n",
    "\n",
    "#How to define with multi-class recall, precision and F1 score?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FMNIST Data\n",
    "def prepareFMNISTData(scale = 0):\n",
    "    from mnist import MNIST\n",
    "    mndata = MNIST('fashion_data')\n",
    "    imagesTrain,labelsTrain = mndata.load_training()\n",
    "    imagesTest, labelsTest = mndata.load_testing()\n",
    "\n",
    "    X_test = np.array(imagesTest)\n",
    "    y_test = np.array(labelsTest)\n",
    "\n",
    "    import random\n",
    "    n = len(imagesTrain)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    indices = np.random.permutation(n)\n",
    "\n",
    "    trainingIndex = indices[:int(4*n/5)]\n",
    "    validationIndex = indices[int(4*n/5):]\n",
    "\n",
    "    X_train = np.array(imagesTrain)[trainingIndex]\n",
    "    y_train = np.array(labelsTrain)[trainingIndex]\n",
    "    \n",
    "    X_val = np.array(imagesTrain)[validationIndex]\n",
    "    y_val = np.array(labelsTrain)[validationIndex]\n",
    "    \n",
    "    if(scale == 1):\n",
    "        mean = np.mean(X_train, axis = 0)\n",
    "        X_train = X_train - mean\n",
    "        X_test = X_test - mean\n",
    "        X_val = X_val - mean\n",
    "        \n",
    "        variance = np.var(X_train, axis = 0)\n",
    "        X_train = X_train/np.sqrt(variance)\n",
    "        X_test = X_test/np.sqrt(variance)\n",
    "        X_val = X_val/np.sqrt(variance)\n",
    "\n",
    "\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test) \n",
    "\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareFMNISTData();\n",
    "\n",
    "\n",
    "print(\"Train, Validation, Test\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareFMNISTData();\n",
    "n_samples = 5\n",
    "print(\"n_samples = \", n_samples)\n",
    "indices = random.sample(range(0, 10000), n_samples)\n",
    "\n",
    "for K in [1000, 100, 25, 5]:\n",
    "    start = time.time()\n",
    "    y_pred = knnClassifier(X_test[indices], X_train, y_train, K, euclideanDistance )\n",
    "    acc = accuracy(y_pred, y_test[indices])\n",
    "    end = time.time()\n",
    "    #print(\"K: \", K)\n",
    "    print(\"accuracy: \", acc)\n",
    "    print(\"time taken: \", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MEDICAL DATA\n",
    "def prepareMedicalData(scale = 0):\n",
    "    medicalData = pd.read_csv('Medical_data.csv')\n",
    "    \n",
    "    '''\n",
    "    print(\"GROUPED Mean\")\n",
    "    print(medicalData[['Health', 'TEST1', 'TEST2', 'TEST3']].groupby('Health').mean())\n",
    "    print(\"GROUPED Standard Deviation\")\n",
    "    print(medicalData[['Health', 'TEST1', 'TEST2', 'TEST3']].groupby('Health').std())\n",
    "    '''\n",
    "\n",
    "    medicalData['Health'] = medicalData['Health'].map({'HEALTHY': 0, 'MEDICATION': 1, 'SURGERY': 2}).astype(int)\n",
    "# Healthy == 0\n",
    "# Medication == 1\n",
    "# Surgery == 2\n",
    "    X = medicalData.values[::, 1::]\n",
    "    y = medicalData.values[::, 0].astype(int)\n",
    "\n",
    "    n = X.shape[0]\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    indices = np.random.permutation(n)\n",
    "    trainingIndex = indices[:int(4*n/6)]\n",
    "    validationIndex = indices[int(4*n/6): int(5*n/6)]\n",
    "    testIndex = indices[int(5*n/6):]\n",
    "\n",
    "    X_train = X[trainingIndex]\n",
    "    y_train = y[trainingIndex]\n",
    "\n",
    "    if(scale == 1):\n",
    "        mean = np.mean(X_train, axis = 0)\n",
    "        X = X - mean\n",
    "        variance = np.var(X_train, axis = 0)\n",
    "        X = X/np.sqrt(variance)\n",
    "        \n",
    "        X_train = X[trainingIndex]\n",
    "        y_train = y[trainingIndex]\n",
    "        \n",
    "    \n",
    "    X_val = X[validationIndex]\n",
    "    y_val = y[validationIndex]\n",
    "\n",
    "    X_test = X[testIndex]\n",
    "    y_test = y[testIndex]\n",
    "\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareMedicalData()\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Train, Validation, Test\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareMedicalData(0)\n",
    "for K in [1, 3, 10, 30, 100, 300]:\n",
    "    start = time.time()\n",
    "    y_pred = knnClassifier(X_val, X_train, y_train, K, euclideanDistance )\n",
    "    acc = accuracy(y_pred, y_val)\n",
    "    end = time.time()\n",
    "    print(\"K: \", K)\n",
    "    print(\"accuracy_validation: \", acc)\n",
    "    #print(\"time taken: \", end-start)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "#Accuracy peaks for K=1\n",
    "K = 1\n",
    "y_pred = knnClassifier(X_test, X_train, y_train, K, euclideanDistance )\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(\"K: \", K)\n",
    "print(\"accuracy_test: \", acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized KNN\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareMedicalData(1)\n",
    "for K in [1, 3, 10, 30, 100, 300]:\n",
    "    start = time.time()\n",
    "    y_pred = knnClassifier(X_val, X_train, y_train, K, euclideanDistance )\n",
    "    acc = accuracy(y_pred, y_val)\n",
    "    end = time.time()\n",
    "    print(\"K: \", K)\n",
    "    print(\"accuracy_validation: \", acc)\n",
    "    #print(\"time taken: \", end-start)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "#Accuracy peaks for K=1\n",
    "K = 1\n",
    "y_pred = knnClassifier(X_test, X_train, y_train, K, euclideanDistance )\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(\"K: \", K)\n",
    "print(\"accuracy_test: \", acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ParzenWindow Bayes\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareMedicalData(1)\n",
    "for H in [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]:\n",
    "    start = time.time()\n",
    "    y_pred = bayesClassifier(X_val, X_train, y_train, parzenWindowEstimation_gaussian, H)\n",
    "    acc = accuracy(y_pred, y_val)\n",
    "    end = time.time()\n",
    "    print(\"H: \", H)\n",
    "    print(\"accuracy_validation: \", acc)\n",
    "    print(\"time taken: \", end-start)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "#Accuracy peaks for H = 0.1\n",
    "H = 0.1\n",
    "y_pred = bayesClassifier(X_test, X_train, y_train, parzenWindowEstimation_gaussian, H)\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(\"H: \", H)\n",
    "print(\"accuracy_test: \", acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RAILWAY BOOKING DATA\n",
    "\n",
    "#membercount from 0 to 10, add 1\n",
    "#preferredClass : FIRST_AC, NO_PREF, SECOND_AC, THIRD_AC\n",
    "#Age is age category 0 to 8\n",
    "\n",
    "def prepareRailwayData(scale = 0):\n",
    "    railwayData = pd.read_csv('railwayBookingList.csv')\n",
    "\n",
    "    railwayData['sex'] = railwayData['sex'].map({'female': 1, 'male': 0})\n",
    "    railwayData.fillna(0, inplace = True)\n",
    "    railwayData['memberCount'] = railwayData['memberCount'] + 1\n",
    "    railwayData['preferredClass'] = railwayData['preferredClass'].map({'FIRST_AC': 3, 'SECOND_AC': 2, 'THIRD_AC': 1, 'NO_PREF': 0})\n",
    "\n",
    "    X = railwayData.values[::, 2::]\n",
    "    y = railwayData.values[::, 1].astype(int)\n",
    "                \n",
    "        \n",
    "    n = X.shape[0]\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    indices = np.random.permutation(n)\n",
    "    trainingIndex = indices[:int(4*n/6)]\n",
    "    validationIndex = indices[int(4*n/6): int(5*n/6)]\n",
    "    testIndex = indices[int(5*n/6):]\n",
    "\n",
    "    X_train = X[trainingIndex]\n",
    "    y_train = y[trainingIndex]\n",
    "\n",
    "    if(scale == 1):\n",
    "        mean = np.mean(X_train, axis = 0)\n",
    "        X = X - mean\n",
    "        variance = np.var(X_train, axis = 0)\n",
    "        X = X/np.sqrt(variance)\n",
    "        \n",
    "        X_train = X[trainingIndex]\n",
    "        y_train = y[trainingIndex]\n",
    "\n",
    "            \n",
    "    X_val = X[validationIndex]\n",
    "    y_val = y[validationIndex]\n",
    "    \n",
    "    X_test = X[testIndex]\n",
    "    y_test = y[testIndex]\n",
    "\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareRailwayData()\n",
    "#print(railwayData.head())\n",
    "#print()\n",
    "#print(\"GROUPED Mean\")\n",
    "#print(railwayData[['boarded', 'budget', 'preferredClass', 'memberCount', 'sex', 'age']].groupby('sex').mean())\n",
    "#print()\n",
    "print(\"Train, Validation, Test\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Unnormalized KNN with Euclidean Distance\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareRailwayData(scale = 0)\n",
    "for K in [1, 3, 10, 30, 100, 300]:\n",
    "    start = time.time()\n",
    "    y_pred = knnClassifier(X_val, X_train, y_train, K, euclideanDistance )\n",
    "    acc = accuracy(y_pred, y_val)\n",
    "    end = time.time()\n",
    "    print(\"K: \", K)\n",
    "    print(\"accuracy_validation: \", acc)\n",
    "    #print(\"time taken: \", end-start)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "#Accuracy peaks for K=3\n",
    "K = 3\n",
    "y_pred = knnClassifier(X_test, X_train, y_train, K, euclideanDistance )\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(\"K: \", K)\n",
    "print(\"accuracy_test: \", acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Normalized KNN with Euclidean Distance\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = prepareRailwayData(scale = 1)\n",
    "for K in [1, 3, 10, 30, 100, 300]:\n",
    "    start = time.time()\n",
    "    y_pred = knnClassifier(X_val, X_train, y_train, K, euclideanDistance )\n",
    "    acc = accuracy(y_pred, y_val)\n",
    "    end = time.time()\n",
    "    print(\"K: \", K)\n",
    "    print(\"accuracy_validation: \", acc)\n",
    "    #print(\"time taken: \", end-start)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "#Accuracy peaks for K=30\n",
    "K = 300\n",
    "y_pred = knnClassifier(X_test, X_train, y_train, K, euclideanDistance)\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(\"K: \", K)\n",
    "print(\"accuracy_test: \", acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10000)\n",
    "%timeit np.square(a)\n",
    "%timeit np.multiply(a.transpose(), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "for idx, i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
